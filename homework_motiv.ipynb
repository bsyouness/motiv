{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motiv Data Scientist/Algorithm Engineer Interview Assignment "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Disclaimer**: This is loosely built around a [machine learning crash course](https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/programming-exercises) and [TensorFlow tutorial](https://www.tensorflow.org/get_started/get_started_for_beginners)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and modify the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firt things first, import the modules we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what's inside our zip file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HW Data/',\n",
       " 'HW Data/hw_file_1.csv',\n",
       " 'HW Data/hw_file_10.csv',\n",
       " 'HW Data/hw_file_2.csv',\n",
       " 'HW Data/hw_file_3.csv',\n",
       " 'HW Data/hw_file_4.csv',\n",
       " 'HW Data/hw_file_5.csv',\n",
       " 'HW Data/hw_file_6.csv',\n",
       " 'HW Data/hw_file_7.csv',\n",
       " 'HW Data/hw_file_8.csv',\n",
       " 'HW Data/hw_file_9.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_folder = zipfile.ZipFile(\"Algorithm_DSdata.zip\", \"r\")\n",
    "zip_folder.namelist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at what the first file look like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1446833694,0.59375,-0.76562,-0.26562,\\n1446833694.0183,0.59375,-0.76562,-0.26562,\\n1446833694.0367,0.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_file = zip_folder.namelist()[1]\n",
    "zip_folder.read(first_file)[:100].decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're told that the data is as follows:\n",
    "1. UTC. The data is sampled roughly at 50Hz. Feel free to assume all data was\n",
    "uniformly at 50Hz, but please be prepared to discuss the ramification of this\n",
    "assumption.\n",
    "2. Acceleration in g’s for the x-axis of an accelerometer. Values will be positive or\n",
    "negative.\n",
    "3. Acceleration in g’s for the y-axis of an accelerometer. Values will be positive or\n",
    "negative.\n",
    "4. Acceleration in g’s for the z-axis of an accelerometer. Values will be positive or\n",
    "negative.\n",
    "5. Activity label. This element will either be blank or contain either “walk” or “run”. Any\n",
    "element with a blank label is considered to be neither walking nor running.\n",
    "\n",
    "Considering that, let's load an aggregated dataframe (the files aren't too large, so it shouldn't be a problem to keep that in memory). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = 'utc, x, y, z, label'.split(', ')\n",
    "df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "for file_name in zip_folder.namelist()[1:]:\n",
    "    csv = StringIO(zip_folder.read(file_name).decode(\"utf-8\"))\n",
    "    data = pd.read_csv(csv, header=None, names=column_names, encoding=\"utf-8\")    \n",
    "    df = pd.concat([df, data], axis=0)\n",
    "\n",
    "zip_folder.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what `df` looks like. It's not surprising that the label contains a lot of `NaN`s..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.60938</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.60938</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            utc        x        y        z label\n",
       "0  1.446834e+09  0.59375 -0.76562 -0.26562   NaN\n",
       "1  1.446834e+09  0.59375 -0.76562 -0.26562   NaN\n",
       "2  1.446834e+09  0.59375 -0.76562 -0.26562   NaN\n",
       "3  1.446834e+09  0.60938 -0.76562 -0.26562   NaN\n",
       "4  1.446834e+09  0.60938 -0.76562 -0.26562   NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, 'Walk', 'Run'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to convert the label to an integer to train our model, might as well do that here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.label.replace({'Walk': 0, 'Run': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled, to_predict = df.loc[~df.label.isna()], df.loc[df.label.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106973</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>-0.70312</td>\n",
       "      <td>-0.79688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106974</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>-0.67188</td>\n",
       "      <td>-0.90625</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106975</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.359380</td>\n",
       "      <td>-0.60938</td>\n",
       "      <td>-1.06250</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106976</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.140620</td>\n",
       "      <td>-0.62500</td>\n",
       "      <td>-1.15620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106977</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.56250</td>\n",
       "      <td>-1.03120</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 utc         x        y        z  label\n",
       "106973  1.446836e+09 -0.281250 -0.70312 -0.79688    0.0\n",
       "106974  1.446836e+09 -0.437500 -0.67188 -0.90625    0.0\n",
       "106975  1.446836e+09 -0.359380 -0.60938 -1.06250    0.0\n",
       "106976  1.446836e+09 -0.140620 -0.62500 -1.15620    0.0\n",
       "106977  1.446836e+09  0.015625 -0.56250 -1.03120    0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops! `label` is a `float` because of the `NaN`s in that column. \n",
    "Now that we removed those, let's convert `label` to `int`s. Again, this is required by TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\generic.py:4401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "labelled.label = labelled.label.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>106973</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.281250</td>\n",
       "      <td>-0.70312</td>\n",
       "      <td>-0.79688</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106974</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.437500</td>\n",
       "      <td>-0.67188</td>\n",
       "      <td>-0.90625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106975</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.359380</td>\n",
       "      <td>-0.60938</td>\n",
       "      <td>-1.06250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106976</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>-0.140620</td>\n",
       "      <td>-0.62500</td>\n",
       "      <td>-1.15620</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106977</th>\n",
       "      <td>1.446836e+09</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>-0.56250</td>\n",
       "      <td>-1.03120</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 utc         x        y        z  label\n",
       "106973  1.446836e+09 -0.281250 -0.70312 -0.79688      0\n",
       "106974  1.446836e+09 -0.437500 -0.67188 -0.90625      0\n",
       "106975  1.446836e+09 -0.359380 -0.60938 -1.06250      0\n",
       "106976  1.446836e+09 -0.140620 -0.62500 -1.15620      0\n",
       "106977  1.446836e+09  0.015625 -0.56250 -1.03120      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our label in now an `int`, we can pursue..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Lr6wYl2bt2Ep",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Build the model\n",
    "\n",
    "In this exercise, we'll try to predict whether a record corresponds to `Walk` or `Run`, which will be our label. We'll use `x`, `y` and `z` as our input features.\n",
    "\n",
    "To train our model, we'll use the TensorFlow [Estimator](https://www.tensorflow.org/get_started/estimator) API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0cpcsieFhsNI"
   },
   "source": [
    "### Step 1: Define features and configure feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "rhEbFCZ86cDZ"
   },
   "outputs": [],
   "source": [
    "# Define the input features.\n",
    "feature_columns = 'x, y, z'.split(', ')\n",
    "\n",
    "# Feature columns describe how to use the input.\n",
    "my_feature_columns = []\n",
    "for column_name in feature_columns:\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=column_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-0IztwdK2f3F"
   },
   "source": [
    "### Step 3: Define the Input Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S5M5j6xSCHxx"
   },
   "source": [
    "The input function instructs TensorFlow how to preprocess\n",
    "the data, as well as how to batch, shuffle, and repeat it during model training.\n",
    "\n",
    "First, we'll convert our *pandas* feature data into a dict of NumPy arrays. We can then use the TensorFlow [Dataset API](https://www.tensorflow.org/programmers_guide/datasets) to construct a dataset object from our data, and then break\n",
    "our data into batches of `batch_size`, to be repeated for the specified number of epochs (num_epochs). \n",
    "\n",
    "**NOTE:** When the default value of `num_epochs=None` is passed to `repeat()`, the input data will be repeated indefinitely.\n",
    "\n",
    "Next, if `shuffle` is set to `True`, we'll shuffle the data so that it's passed to the model randomly during training. The `buffer_size` argument specifies\n",
    "the size of the dataset from which `shuffle` will randomly sample.\n",
    "\n",
    "Finally, our input function constructs an iterator for the dataset and returns the next batch of data to our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "RKZ9zNcHJtwc"
   },
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels, batch_size, shuffle=True, num_epochs=None):\n",
    "    \"\"\"An input function for training.\n",
    "\n",
    "    Args:\n",
    "      features: pandas DataFrame of features\n",
    "      labels: pandas DataFrame of targets\n",
    "      batch_size: Size of batches to be passed to the model\n",
    "      shuffle: True or False. Whether to shuffle the data.\n",
    "      num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\n",
    "    Returns:\n",
    "      Tuple of (features, labels) for next data batch\n",
    "    \"\"\"\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle the data, if specified.\n",
    "    if shuffle:\n",
    "      dataset = dataset.shuffle(buffer_size=10000)\n",
    "    \n",
    "    dataset.map(lambda x: tf.random_crop(x, (TIMESERIES_SIZE, )))\n",
    "\n",
    "    # Shuffle, repeat, and batch the examples.\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "\n",
    "    # Should I use this?\n",
    "    # Return the next batch of data.\n",
    "    features, labels = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "    # Return the dataset.\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YS50CQb2ooO"
   },
   "source": [
    "### Step 5: Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\bsyou\\AppData\\Local\\Temp\\tmp70gpc2ne\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\bsyou\\\\AppData\\\\Local\\\\Temp\\\\tmp70gpc2ne', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000019441BDFFD0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Build 2 hidden layer DNN with 10, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=my_feature_columns,\n",
    "    # Two hidden layers of 10 nodes each.\n",
    "    hidden_units=[40, 40],\n",
    "    # The model must choose between 3 classes.\n",
    "    n_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4YS50CQb2ooO"
   },
   "source": [
    "### Step 4: Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yP92XkzhU803"
   },
   "source": [
    "First we need to separate training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of labelled data: 45.7%\n"
     ]
    }
   ],
   "source": [
    "print('Fraction of labeled data: {0:.1%}'.format(float(len(labeled))/len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(labelled, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = train[feature_columns], train['label']\n",
    "test_x, test_y = test[feature_columns], test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\bsyou\\AppData\\Local\\Temp\\tmp70gpc2ne\\model.ckpt.\n",
      "INFO:tensorflow:loss = 77.65143, step = 0\n",
      "INFO:tensorflow:global_step/sec: 179.026\n",
      "INFO:tensorflow:loss = 4.809237, step = 100 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 394.753\n",
      "INFO:tensorflow:loss = 15.169634, step = 200 (0.253 sec)\n",
      "INFO:tensorflow:global_step/sec: 399.473\n",
      "INFO:tensorflow:loss = 3.6578286, step = 300 (0.250 sec)\n",
      "INFO:tensorflow:global_step/sec: 419.992\n",
      "INFO:tensorflow:loss = 4.665278, step = 400 (0.238 sec)\n",
      "INFO:tensorflow:global_step/sec: 421.292\n",
      "INFO:tensorflow:loss = 15.00949, step = 500 (0.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 426.169\n",
      "INFO:tensorflow:loss = 6.0020413, step = 600 (0.235 sec)\n",
      "INFO:tensorflow:global_step/sec: 391.67\n",
      "INFO:tensorflow:loss = 2.8234093, step = 700 (0.255 sec)\n",
      "INFO:tensorflow:global_step/sec: 414.329\n",
      "INFO:tensorflow:loss = 10.978325, step = 800 (0.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 417.781\n",
      "INFO:tensorflow:loss = 2.7346745, step = 900 (0.239 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\bsyou\\AppData\\Local\\Temp\\tmp70gpc2ne\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.256557.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x19441bdf4a8>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DNN parameters.\n",
    "batch_size = 100\n",
    "train_steps = 1000\n",
    "\n",
    "# Train the Model.\n",
    "classifier.train(\n",
    "    input_fn=lambda:train_input_fn(train_x, train_y, batch_size), steps=train_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Nwxqxlx2sOv"
   },
   "source": [
    "### Step 6: Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KoDaF2dlJQG5"
   },
   "source": [
    "Let's make predictions on that training data, to see how well our model fit it during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels, batch_size):\n",
    "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "    features=dict(features)\n",
    "    if labels is None:\n",
    "        # No labels, use only features.\n",
    "        inputs = features\n",
    "    else:\n",
    "        inputs = (features, labels)\n",
    "\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
    "\n",
    "    # Batch the examples\n",
    "    assert batch_size is not None, \"batch_size must not be None\"\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Return the dataset.\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-30-05:35:44\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\bsyou\\AppData\\Local\\Temp\\tmp70gpc2ne\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-30-05:35:49\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9748281, accuracy_baseline = 0.96066004, auc = 0.93429714, auc_precision_recall = 0.6543493, average_loss = 0.08486344, global_step = 1000, label/mean = 0.039339956, loss = 8.4841, precision = 0.88860106, prediction/mean = 0.032180455, recall = 0.4117647\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(test_x, test_y, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-30-05:35:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\bsyou\\AppData\\Local\\Temp\\tmp70gpc2ne\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-30-05:36:14\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.97402024, accuracy_baseline = 0.96027476, auc = 0.93045187, auc_precision_recall = 0.640741, average_loss = 0.087585606, global_step = 1000, label/mean = 0.039725233, loss = 8.758229, precision = 0.87549996, prediction/mean = 0.0324, recall = 0.40337634\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model.\n",
    "eval_result = classifier.evaluate(\n",
    "    input_fn=lambda:eval_input_fn(train_x, train_y, batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "pDIxp6vcU809"
   },
   "outputs": [],
   "source": [
    "# Create an input function for predictions.\n",
    "# Note: Since we're making just one prediction for each example, we don't \n",
    "# need to repeat or shuffle the data here.\n",
    "prediction_input_fn = lambda: train_input_fn(features, , num_epochs=1, shuffle=False)\n",
    "\n",
    "# Call predict() on the linear_regressor to make predictions.\n",
    "predictions = classifier.predict(input_fn=prediction_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f8642db4be76>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Format predictions as a NumPy array, so we can calculate error metrics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print Mean Squared Error and Root Mean Squared Error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmean_squared_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-f8642db4be76>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Format predictions as a NumPy array, so we can calculate error metrics.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'predictions'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Print Mean Squared Error and Root Mean Squared Error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmean_squared_error\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       features, input_hooks = self._get_features_from_input_fn(\n\u001b[1;32m--> 494\u001b[1;33m           input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[0m\u001b[0;32m    495\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m    496\u001b[0m           features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m    668\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_features_from_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[1;34m\"\"\"Extracts the `features` from return values of `input_fn`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m     \u001b[0minput_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m    796\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-37b2564322d9>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Note: Since we're making just one prediction for each example, we don't\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# need to repeat or shuffle the data here.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprediction_input_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Call predict() on the linear_regressor to make predictions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'my_feature' is not defined"
     ]
    }
   ],
   "source": [
    "# Format predictions as a NumPy array, so we can calculate error metrics.\n",
    "predictions = np.array([item['predictions'][0] for item in predictions])\n",
    "\n",
    "# Print Mean Squared Error and Root Mean Squared Error.\n",
    "mean_squared_error = metrics.mean_squared_error(predictions, targets)\n",
    "root_mean_squared_error = math.sqrt(mean_squared_error)\n",
    "# print \"Mean Squared Error (on training data): {0:%0.3f}\".format(mean_squared_error)\n",
    "# print \"Root Mean Squared Error (on training data): %0.3f\" % root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.utc = pd.to_datetime(df.utc, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-11-06 18:14:54.000000</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-11-06 18:14:54.018300</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-11-06 18:14:54.036700</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-11-06 18:14:54.055000</td>\n",
       "      <td>0.60938</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-06 18:14:54.073400</td>\n",
       "      <td>0.60938</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         utc        x        y        z  label\n",
       "0 2015-11-06 18:14:54.000000  0.59375 -0.76562 -0.26562    NaN\n",
       "1 2015-11-06 18:14:54.018300  0.59375 -0.76562 -0.26562    NaN\n",
       "2 2015-11-06 18:14:54.036700  0.59375 -0.76562 -0.26562    NaN\n",
       "3 2015-11-06 18:14:54.055000  0.60938 -0.76562 -0.26562    NaN\n",
       "4 2015-11-06 18:14:54.073400  0.60938 -0.76562 -0.26562    NaN"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1157700, 5)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(529356, 5)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AKWstXXPzOVz",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Is this a good model? How would you judge how large this error is?\n",
    "\n",
    "Mean Squared Error (MSE) can be hard to interpret, so we often look at Root Mean Squared Error (RMSE)\n",
    "instead.  A nice property of RMSE is that it can be interpreted on the same scale as the original targets.\n",
    "\n",
    "Let's compare the RMSE to the difference of the min and max of our targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "7UwqGbbxP53O"
   },
   "outputs": [],
   "source": [
    "min_house_value = california_housing_dataframe[\"median_house_value\"].min()\n",
    "max_house_value = california_housing_dataframe[\"median_house_value\"].max()\n",
    "min_max_difference = max_house_value - min_house_value\n",
    "\n",
    "print \"Min. Median House Value: %0.3f\" % min_house_value\n",
    "print \"Max. Median House Value: %0.3f\" % max_house_value\n",
    "print \"Difference between Min. and Max.: %0.3f\" % min_max_difference\n",
    "print \"Root Mean Squared Error: %0.3f\" % root_mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JigJr0C7Pzit"
   },
   "source": [
    "Our error spans nearly half the range of the target values. Can we do better?\n",
    "\n",
    "This is the question that nags at every model developer. Let's develop some basic strategies to reduce model error.\n",
    "\n",
    "The first thing we can do is take a look at how well our predictions match our targets, in terms of overall summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "941nclxbzqGH",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "calibration_data = pd.DataFrame()\n",
    "calibration_data[\"predictions\"] = pd.Series(predictions)\n",
    "calibration_data[\"targets\"] = pd.Series(targets)\n",
    "calibration_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E2-bf8Hq36y8",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Okay, maybe this information is helpful. How does the mean value compare to the model's RMSE? How about the various quantiles?\n",
    "\n",
    "We can also visualize the data and the line we've learned.  Recall that linear regression on a single feature can be drawn as a line mapping input *x* to output *y*.\n",
    "\n",
    "First, we'll get a uniform random sample of the data so we can make a readable scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "SGRIi3mAU81H"
   },
   "outputs": [],
   "source": [
    "sample = california_housing_dataframe.sample(n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N-JwuJBKU81J"
   },
   "source": [
    "Next, we'll plot the line we've learned, drawing from the model's bias term and feature weight, together with the scatter plot. The line will show up red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "test": {
      "output": "ignore",
      "timeout": 600
     }
    },
    "colab_type": "code",
    "id": "7G12E76-339G",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Get the min and max total_rooms values.\n",
    "x_0 = sample[\"total_rooms\"].min()\n",
    "x_1 = sample[\"total_rooms\"].max()\n",
    "\n",
    "# Retrieve the final weight and bias generated during training.\n",
    "weight = linear_regressor.get_variable_value('linear/linear_model/total_rooms/weights')[0]\n",
    "bias = linear_regressor.get_variable_value('linear/linear_model/bias_weights')\n",
    "\n",
    "# Get the predicted median_house_values for the min and max total_rooms values.\n",
    "y_0 = weight * x_0 + bias \n",
    "y_1 = weight * x_1 + bias\n",
    "\n",
    "# Plot our regression line from (x_0, y_0) to (x_1, y_1).\n",
    "plt.plot([x_0, x_1], [y_0, y_1], c='r')\n",
    "\n",
    "# Label the graph axes.\n",
    "plt.ylabel(\"median_house_value\")\n",
    "plt.xlabel(\"total_rooms\")\n",
    "\n",
    "# Plot a scatter plot from our data sample.\n",
    "plt.scatter(sample[\"total_rooms\"], sample[\"median_house_value\"])\n",
    "\n",
    "# Display graph.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t0lRt4USU81L"
   },
   "source": [
    "This initial line looks way off.  See if you can look back at the summary stats and see the same information encoded there.\n",
    "\n",
    "Together, these initial sanity checks suggest we may be able to find a much better line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py:3694: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "to_predict.drop(columns='label', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>utc</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.59375</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.60938</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.446834e+09</td>\n",
       "      <td>0.60938</td>\n",
       "      <td>-0.76562</td>\n",
       "      <td>-0.26562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            utc        x        y        z\n",
       "0  1.446834e+09  0.59375 -0.76562 -0.26562\n",
       "1  1.446834e+09  0.59375 -0.76562 -0.26562\n",
       "2  1.446834e+09  0.59375 -0.76562 -0.26562\n",
       "3  1.446834e+09  0.60938 -0.76562 -0.26562\n",
       "4  1.446834e+09  0.60938 -0.76562 -0.26562"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = ['Walk', 'Run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = classifier.predict(\n",
    "    input_fn=lambda:eval_input_fn(to_predict[feature_columns], labels=None, batch_size=batch_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Estimator.predict at 0x000001AE02F49678>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions\n",
    "        class_id = pred_dict['class_ids'][0]\n",
    "        probability = pred_dict['probabilities'][class_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\bsyou\\AppData\\Local\\Temp\\tmpb_r4u6yk\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "0 98.76295328140259 Walk\n",
      "0 98.76295328140259 Run\n"
     ]
    }
   ],
   "source": [
    "for pred_dict, expec in zip(predictions, expected):\n",
    "        class_id = pred_dict['class_ids'][0]\n",
    "        probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "        print(class_id, 100 * probability, expec)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "JndnmDMp66FL",
    "ajVM7rkoYXeL",
    "ci1ISxxrZ7v0"
   ],
   "default_view": {},
   "name": "first_steps_with_tensor_flow.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
